{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import typing as tp\n",
    "from itertools import product\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import savgol_filter\n",
    "\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "import sklearn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пути и прочие константы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_PATH = '/home/jupyter-igor_busov/Seed/Hyperspectral/data/pigment/'\n",
    "IMG_PATH_WHITE = IMG_PATH + 'white/'\n",
    "IMG_PATH_COLORED = IMG_PATH + 'colored/'\n",
    "CALIBR_WHITE_PATH_WHITE = IMG_PATH_WHITE + 'White_session_000_000_cube.tiff'\n",
    "CALIBR_BLACK_PATH_WHITE = IMG_PATH_WHITE + 'Black_session_000_004_snapshot_cube.tiff'\n",
    "CALIBR_WHITE_PATH_COLORED = IMG_PATH_COLORED + 'White_session_000_000_snapshot_cube.tiff'\n",
    "CALIBR_BLACK_PATH_COLORED = IMG_PATH_COLORED + 'Black_session_000_001_snapshot_cube.tiff'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Код}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таблица с информацией о пигментном составе цветных изображений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_pigment = pd.read_csv(IMG_PATH + 'colored_pigment.csv')\n",
    "colored_pigment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = [ 'меланин', 'Unnamed: 3', 'антоцианы', 'Unnamed: 5', 'Unnamed: 8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_pigment = colored_pigment[needed_columns].iloc[1:].rename(columns={ 'меланин': 'melanin_scales', \n",
    "                                                                    'Unnamed: 3': 'melanin_pericarp',\n",
    "                                                                    'антоцианы': 'anthocyanins_scales',\n",
    "                                                                    'Unnamed: 5': 'anthocyanins_pericarp',\n",
    "                                                                    'Unnamed: 8': 'file_name'\n",
    "                                                                }).reset_index(drop=True)\n",
    "colored_pigment = colored_pigment.replace(['нет', 'да'], [0, 1])\n",
    "colored_pigment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colored_pigment['melanin'] = (colored_pigment['melanin_scales']\n",
    "                              + colored_pigment['melanin_pericarp']).clip(0,1)\n",
    "colored_pigment['anthocyanins'] = (colored_pigment['anthocyanins_scales']\n",
    "                              + colored_pigment['anthocyanins_pericarp']).clip(0,1)\n",
    "colored_pigment.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "класс, описывающий гиперспектральное изображение с основными используемыми в этой работе методами "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hyper_Img:\n",
    "    \"\"\"\n",
    "    Hyperspectral image with basic methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path: str, threshold_value: float = 7.5, \n",
    "                 savgol_par: tp.Tuple[int] = (9, 3)) -> None:\n",
    "        self.savgol_par = savgol_par\n",
    "        self._threshold_value = threshold_value\n",
    "        self.path = path\n",
    "        self.img = self._get_tiff()\n",
    "        self.widht = self.img.shape[0]\n",
    "        self.height = self.img.shape[1]\n",
    "        self.pixels =  self._get_pixels()\n",
    "        self.medians = self._get_medians()\n",
    "        self.melanin, self.anthocyanins  = self._get_pigment()\n",
    "        self.pigment: str = 'white'\n",
    "        if self.melanin and self.anthocyanins:\n",
    "            self.pigment = 'melanin and anthocyanins'\n",
    "        elif self.melanin:\n",
    "            self.pigment = 'only melanin'\n",
    "        elif self.anthocyanins:\n",
    "            self.pigment = 'only anthocyanins'\n",
    "    \n",
    "    @staticmethod\n",
    "    def wave_len(x: int, step: int = 4, begin_wave_len: int = 450) -> int:\n",
    "        return int((x - begin_wave_len) // step)\n",
    "    \n",
    "    def _get_tiff(self) -> None:\n",
    "        img = tiff.imread(self.path)\n",
    "        if set(IMG_PATH_WHITE.split('/')).issubset(set(self.path.split('/'))):\n",
    "            bl_img = tiff.imread(CALIBR_BLACK_PATH_WHITE)\n",
    "            wh_img = tiff.imread(CALIBR_WHITE_PATH_WHITE)\n",
    "        else:\n",
    "            bl_img = tiff.imread(CALIBR_BLACK_PATH_COLORED)\n",
    "            wh_img = tiff.imread(CALIBR_WHITE_PATH_COLORED)\n",
    "        new_img = np.where(bl_img > img, 0, img - bl_img)\n",
    "        return new_img /(wh_img - bl_img)\n",
    "    \n",
    "    def _get_pigment(self) -> tp.Tuple[int, int]:\n",
    "        if not set(IMG_PATH.split('/')).issubset(set(self.path.split('.')[0].split('/'))):\n",
    "            raise NameError('Error in path')\n",
    "            \n",
    "        if np.any(np.isnan(self.medians)):\n",
    "            return -3, -3\n",
    "        \n",
    "        if np.allclose(self.medians, np.ones(len(self.medians), dtype=float)) or \\\n",
    "           np.allclose(self.medians, np.zeros(len(self.medians), dtype=float)): \n",
    "            return -1, -1\n",
    "        \n",
    "        if set(IMG_PATH_WHITE.split('/')).issubset(set(self.path.split('/'))):\n",
    "            return 0, 0\n",
    "    \n",
    "        name: str = '_'.join([s for s in self.path.split('/')[-1].split('_')\n",
    "                        if s != 'snapshot' and s != 'cube.tiff' ])\n",
    "            \n",
    "        if name not in np.unique(colored_pigment.file_name):\n",
    "            return -2, -2\n",
    "        \n",
    "        return colored_pigment[colored_pigment.file_name == name].melanin.iloc[0],\\\n",
    "                            colored_pigment[colored_pigment.file_name == name].anthocyanins.iloc[0]\n",
    "        \n",
    "    def _get_pixels(self) -> tp.List[tp.Tuple[int, int]]:\n",
    "        return [(x, y) for x, y in product(range(self.widht), range(self.height)) \n",
    "                if self.threshold_bgr[x,y] != 0]\n",
    "    \n",
    "    def _get_medians(self) -> np.array:\n",
    "        medians: tp.List[float] = list()\n",
    "        for i in range(self.img.shape[2]):\n",
    "            medians.append(np.median(np.array([self.img[p[0]][p[1]][i] for p in self.pixels])))\n",
    "        return savgol_filter(np.array(medians), *self.savgol_par)\n",
    " \n",
    "    @property\n",
    "    def bgr(self) -> np.array:\n",
    "        \n",
    "        #To accurately display colors, you need to choose constants\n",
    "        \n",
    "        im_r = self.img[:,:,Hyper_Img.wave_len(630)]\n",
    "        im_g = self.img[:,:,Hyper_Img.wave_len(510)]\n",
    "        im_b = self.img[:,:,Hyper_Img.wave_len(450)]\n",
    "    \n",
    "        im_r = (im_r / im_r.max())*255\n",
    "        im_g = (im_g / im_g.max())*255\n",
    "        im_b = (im_b / im_b.max())*255\n",
    "    \n",
    "        im_r = np.clip(im_r,0,255).astype(np.uint8)\n",
    "        im_g = np.clip(im_g,0,255).astype(np.uint8)\n",
    "        im_b = np.clip(im_b,0,255).astype(np.uint8)\n",
    "    \n",
    "        im_bgr = np.zeros((self.widht, self.height, 3), dtype = np.uint8)\n",
    "        im_bgr[:,:,0] = im_b\n",
    "        im_bgr[:,:,1] = im_g\n",
    "        im_bgr[:,:,2] = im_r\n",
    "    \n",
    "        return im_bgr\n",
    "    \n",
    "    @property\n",
    "    def threshold_bgr(self) -> np.array:\n",
    "        im_black = cv2.cvtColor(self.bgr, cv2.COLOR_BGR2GRAY)\n",
    "        _, im_thr = cv2.threshold(im_black, self._threshold_value, 255, cv2.THRESH_BINARY)\n",
    "        return im_thr\n",
    "    \n",
    "    def __repr__(self) -> str:\n",
    "        fig, axes = plt.subplots(1, 2)\n",
    "        \n",
    "        axes[0].imshow(self.bgr, cmap = 'gray')\n",
    "        axes[0].set_title('rgb visualization')\n",
    "        \n",
    "        axes[1].imshow(self.threshold_bgr, cmap = 'gray')\n",
    "        axes[1].set_title('segmentation')\n",
    "        \n",
    "        if self.melanin == -1:\n",
    "            return 'pigment: white or black image for calibration'\n",
    "        elif self.melanin < 0:\n",
    "            return 'unknown'\n",
    "        return f'pigment: {self.pigment}'\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Примеры изображений (визуализация не точно передает цвета)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(CALIBR_WHITE_PATH_COLORED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_COLORED + 'session_001_001_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_COLORED + 'session_001_004_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_COLORED + 'session_001_000_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_COLORED + 'session_001_007_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_WHITE + 'session_001_013_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Hyper_Img(IMG_PATH_WHITE + 'session_001_037_snapshot_cube.tiff')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция, возвращающая необходимые имена в директории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def all_tiff_cube_img(path: str) -> tp.List[str]:\n",
    "    img_names: tp.List[str] = list()\n",
    "    for dirname, _, filenames in os.walk(path):\n",
    "        for filename in filenames: \n",
    "            name = os.path.join(filename)\n",
    "            if name.split('.')[-1] != 'tiff':\n",
    "                continue\n",
    "            if name.split('.')[0].split('_')[-1] != 'cube':\n",
    "                continue\n",
    "            img_names.append(dirname + '/' + name)\n",
    "            \n",
    "    return img_names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "считываем все необходимые изображения "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyper_imgs - list with all hyperspectral images\n",
    "hyper_imgs: tp.List[Hyper_Img] = [Hyper_Img(name) for name in all_tiff_cube_img(IMG_PATH)\n",
    "                                   if Hyper_Img(name).melanin >= 0]        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Графики медиан для каждого канала}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_medians(hyper_imgs: tp.List[Hyper_Img]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create DataFrame for graphics\n",
    "    \"\"\"\n",
    "    \n",
    "    x_axis: tp.List[int] = list(np.arange(0,138)*4 + 450)\n",
    "    points: tp.List[tp.Tuple[float, float, int, str]] = list()\n",
    "    \n",
    "    for sample_number, sample in enumerate(hyper_imgs):\n",
    "        \n",
    "        if sample.melanin == -1:\n",
    "            continue\n",
    "        \n",
    "        for p in zip(x_axis, sample.medians):\n",
    "            points.append([p[0], p[1], sample_number, sample.pigment])\n",
    "        \n",
    "\n",
    "    return pd.DataFrame(points, columns = ['Wavelength', 'Median', 'Sample', 'Pigment'])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_med = get_all_medians(hyper_imgs)\n",
    "df_all_med.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.lineplot(data=df_all_med, x='Wavelength', y='Median', hue='Pigment')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{PCA}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Пайплайн\n",
    "feature_pipe = Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_med_df(hyper_imgs: tp.List[Hyper_Img]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create DataFrame for PCA\n",
    "    \"\"\"\n",
    "        \n",
    "    return pd.DataFrame([list(sample.medians) + [sample.pigment] for sample in hyper_imgs], \n",
    "                         columns = list(np.arange(0,138)*4 + 450) + ['Pigment'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_med_df(hyper_imgs)\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Pigment'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Pigment']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "обучение и процент дисперсии для каждой компаненты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = feature_pipe.fit_transform(X)\n",
    "feature_pipe['pca'].explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "визуализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_arr = np.array(tuple(zip(X[:,:2], y['Pigment'])))\n",
    "lst_of_value = [(new_arr[i][0][0], new_arr[i][0][1], new_arr[i][1]) for i, _ in enumerate(new_arr)]\n",
    "pd.DataFrame(lst_of_value, columns = ['1', '2', 'Pigment']).sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.scatterplot(data=pd.DataFrame(lst_of_value, \n",
    "                                  columns=['1', '2', 'Mutation']), x='1', y='2', hue='Mutation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Классификация}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_med_df_bin_classific(hyper_imgs: tp.List[Hyper_Img], class_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create DataFrame for binary classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_class(pigment: str) -> int:\n",
    "        if class_name in pigment:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    return pd.DataFrame([list(sample.medians) + [get_class(sample.pigment)] for sample in hyper_imgs], \n",
    "                         columns = list(np.arange(0,138)*4 + 450) + ['Pigment'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_med_df_multi_classific(hyper_imgs: tp.List[Hyper_Img]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    create DataFrame for multi-class classification\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_class(sample) -> int:\n",
    "        if sample.melanin and sample.anthocyanins:\n",
    "            return 3\n",
    "        elif sample.anthocyanins:\n",
    "            return 2\n",
    "        elif sample.melanin:\n",
    "            return 1\n",
    "        return 0\n",
    "    \n",
    "    return pd.DataFrame([list(sample.medians) + [get_class(sample)] for sample in hyper_imgs\n",
    "                         if sample.melanin >= 0], \n",
    "                         columns = list(np.arange(0,138)*4 + 450) + ['Pigment']) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стратифицированная кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Классификация по наличию меланина}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "информация о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_med_df_bin_classific(hyper_imgs, 'melanin')\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество образцов каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby('Pigment', as_index=True).count()[[450]].rename(columns={450:'Count'}).reset_index()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=df_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разделение выборки на обучающию и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Pigment'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Pigment']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = y_test.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=test_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = y_train.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=train_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('logistic_regr', LogisticRegressionCV(cv=cv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = logistic_regr_pipe['feature'].fit_transform(X_train)\n",
    "X_test = logistic_regr_pipe['feature'].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_random_forest = { 'max_depth':[2, 7], 'min_samples_split': [1, 5], \n",
    "                            'min_samples_leaf': [1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest = GridSearchCV(RandomForestClassifier(n_estimators=150), parameters_random_forest, cv=cv)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('random_forest', clf_forest.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_boosting = { 'learning_rate':np.power(2, np.arange(10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting = GridSearchCV(GradientBoostingClassifier(n_estimators=150), parameters_boosting, cv=cv)\n",
    "clf_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('gradient_boosting', clf_boosting.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "таблица с результатами моделей по основным метрикам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(models: tp.List[sklearn.base.BaseEstimator], models_name: tp.List[str],\n",
    "                X: np.array, y: np.array) -> pd.DataFrame:\n",
    "    y_predicts = [model.predict(X) for model in models]\n",
    "    accuracy: tp.List[float] = [accuracy_score(y, y_predict) for y_predict in y_predicts]\n",
    "    f1: tp.List[float] = [f1_score(y, y_predict) for y_predict in y_predicts]\n",
    "    precision: tp.List[float] = [precision_score(y, y_predict) for y_predict in y_predicts]\n",
    "    recall: tp.List[float] = [recall_score(y, y_predict) for y_predict in y_predicts]\n",
    "    return pd.DataFrame(zip(models_name, accuracy, f1, precision, recall), \n",
    "                        columns = ['model', 'accuracy', 'f1', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тренеровочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Классификация по наличию антоцианов}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_med_df_bin_classific(hyper_imgs, 'anthocyanins')\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество образцов каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby('Pigment', as_index=True).count()[[450]].rename(columns={450:'Count'}).reset_index()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=df_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разделение выборки на обучающию и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Pigment'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Pigment']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = y_test.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=test_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = y_train.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=train_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('logistic_regr', LogisticRegressionCV(cv=cv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = logistic_regr_pipe['feature'].fit_transform(X_train)\n",
    "X_test = logistic_regr_pipe['feature'].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_random_forest = { 'max_depth':[2, 5], 'min_samples_split': [1, 5], \n",
    "                            'min_samples_leaf': [1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest = GridSearchCV(RandomForestClassifier(n_estimators=150), parameters_random_forest, cv=cv)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('random_forest', clf_forest.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_boosting = { 'learning_rate':np.power(2, np.arange(10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting = GridSearchCV(GradientBoostingClassifier(n_estimators=150), parameters_boosting, cv=cv)\n",
    "clf_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('gradient_boosting', clf_boosting.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тренеровочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Классификация по наличию пигмента}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "информация о данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_med_df_bin_classific(hyper_imgs, 'white')\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "количество образцов каждого класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby('Pigment', as_index=True).count()[[450]].rename(columns={450:'Count'}).reset_index()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=df_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разделение выборки на обучающию и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Pigment'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Pigment']]\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = y_test.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=test_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = y_train.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=train_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('logistic_regr', LogisticRegressionCV(cv=cv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = logistic_regr_pipe['feature'].fit_transform(X_train)\n",
    "X_test = logistic_regr_pipe['feature'].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_random_forest = { 'max_depth':[2, 7], 'min_samples_split': [1, 5], \n",
    "                            'min_samples_leaf': [1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest = GridSearchCV(RandomForestClassifier(n_estimators=150), parameters_random_forest, cv=cv)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('random_forest', clf_forest.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_boosting = { 'learning_rate':np.power(2, np.arange(10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting = GridSearchCV(GradientBoostingClassifier(n_estimators=150), parameters_boosting, cv=cv)\n",
    "clf_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('gradient_boosting', clf_boosting.best_estimator_)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тренеровочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\textbf{Мультиклассовая классификация}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = get_med_df_multi_classific(hyper_imgs)\n",
    "df.sample(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_count = df.groupby(['Pigment'], as_index=True).count()[[450]].rename(columns={450:'Count'}).reset_index()\n",
    "df_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=df_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "разделение выборки на обучающию и тестовую"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Pigment'], axis = 1)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df[['Pigment']]\n",
    "y.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_count = y_test.reset_index().groupby('Pigment').count().reset_index().rename(columns={'index':'Count'})\n",
    "test_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=test_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_count = y_train.reset_index().groupby(['Pigment']).count().reset_index().rename(columns={'index':'Count'})\n",
    "train_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,9))\n",
    "sns.barplot(data=train_count, x='Pigment', y='Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Логистическая регрессия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('logistic_regr', LogisticRegressionCV(cv=cv))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = logistic_regr_pipe['feature'].fit_transform(X_train)\n",
    "X_test = logistic_regr_pipe['feature'].transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logistic_regr_pipe['logistic_regr'].intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, logistic_regr_pipe['logistic_regr'].predict(X_test))\n",
    "conf_matrix = pd.DataFrame(conf_matrix, columns=[0, 1, 2, 3])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_random_forest = { 'max_depth':[2, 5], 'min_samples_leaf': [1, 5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest = GridSearchCV(RandomForestClassifier(n_estimators=150), \n",
    "                          parameters_random_forest, cv=cv)\n",
    "clf_forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_forest.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('random_forest', clf_forest.best_estimator_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " random_forest_pipe['random_forest'].n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, random_forest_pipe['random_forest'].predict(X_test))\n",
    "conf_matrix = pd.DataFrame(conf_matrix, columns=[0, 1, 2, 3])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Градиентный бустинг"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_boosting = { 'learning_rate':np.power(2, np.arange(10))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting = GridSearchCV(GradientBoostingClassifier(n_estimators=150), parameters_boosting, cv=cv)\n",
    "clf_boosting.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_boosting.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gradient_boosting_pipe = Pipeline([('feature', Pipeline([('scaler', StandardScaler()), ('pca', PCA(n_components=5))])),\n",
    "                               ('gradient_boosting', clf_boosting.best_estimator_)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " gradient_boosting_pipe['gradient_boosting'].n_classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_matrix = confusion_matrix(y_test, gradient_boosting_pipe['gradient_boosting'].predict(X_test))\n",
    "conf_matrix = pd.DataFrame(conf_matrix, columns=[0, 1, 2, 3])\n",
    "conf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9,7))\n",
    "sns.heatmap(conf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def muticlass_predict_to_multilabel(y: np.array) -> tp.Tuple[np.array, np.array]:\n",
    "    y_first_cl = np.zeros(len(y))\n",
    "    y_second_cl = np.zeros(len(y))\n",
    "    for idx, y_val in enumerate(y):\n",
    "        if y_val == 3:\n",
    "            y_first_cl[idx] = 1\n",
    "            y_second_cl[idx] = 1\n",
    "        elif y_val == 2:\n",
    "            y_first_cl[idx] = 0\n",
    "            y_second_cl[idx] = 1\n",
    "        elif y_val == 1:\n",
    "            y_first_cl[idx] = 1\n",
    "            y_second_cl[idx] = 0\n",
    "    return y_first_cl, y_second_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_metrics(models: tp.List[sklearn.base.BaseEstimator], models_name: tp.List[str],\n",
    "                X: np.array, y: np.array) -> pd.DataFrame:\n",
    "    y_multilabel = muticlass_predict_to_multilabel(y)\n",
    "    y_predicts = [model.predict(X) for model in models]\n",
    "    accuracy: tp.List[float] = [sum([accuracy_score(y_multilabel[i], y_pr) for i, y_pr \n",
    "                                     in enumerate(muticlass_predict_to_multilabel(y_predict))])/len(y_multilabel) \n",
    "                                for y_predict in y_predicts]\n",
    "    f1: tp.List[float] = [sum([f1_score(y_multilabel[i], y_pr) for i, y_pr \n",
    "                                     in enumerate(muticlass_predict_to_multilabel(y_predict))])/len(y_multilabel) \n",
    "                                for y_predict in y_predicts]\n",
    "    precision: tp.List[float] = [sum([precision_score(y_multilabel[i], y_pr) for i, y_pr \n",
    "                                     in enumerate(muticlass_predict_to_multilabel(y_predict))])/len(y_multilabel) \n",
    "                                for y_predict in y_predicts]\n",
    "    recall: tp.List[float] = [sum([recall_score(y_multilabel[i], y_pr) for i, y_pr \n",
    "                                     in enumerate(muticlass_predict_to_multilabel(y_predict))])/len(y_multilabel) \n",
    "                                for y_predict in y_predicts]\n",
    "    return pd.DataFrame(zip(models_name, accuracy, f1, precision, recall), \n",
    "                        columns = ['model', 'accuracy', 'f1', 'precision', 'recall'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тренеровочной выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_average_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_train, y_train['Pigment'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты на тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_average_metrics([logistic_regr_pipe['logistic_regr'], random_forest_pipe['random_forest'], \n",
    "             gradient_boosting_pipe['gradient_boosting']], \n",
    "             ['Логистическая регрессия', 'Random Forest', 'Градиентный бустинг'], X_test, y_test['Pigment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
